{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32a7e680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sadrul\\.conda\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\sadrul\\.conda\\lib\\site-packages (from nltk) (1.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\sadrul\\.conda\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sadrul\\.conda\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: regex in c:\\users\\sadrul\\.conda\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24a26dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk #importing the 'nltk' library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa162541",
   "metadata": {},
   "source": [
    "### Downloading the function 'stopwords' which are words that do not have much signifcance in the sentence like 'he' or 'she'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fb32550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Sadrul\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords') #downloading the function 'stopwords'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388ca9a6",
   "metadata": {},
   "source": [
    "## Importing the Pandas library, which is usually imported when working with large datasets. Then goes on to read the pathway to paste the dataset and saves it to a 'imdb' variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2379b56e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd #Importing another library\n",
    "\n",
    "imdb = pd.read_csv('/Users/Sadrul/Documents/Audacity/CODES/imdb/IMDB Dataset.csv') #Creating a pathway to import the 'IMDB Dataset'\n",
    "(imdb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "167bf112",
   "metadata": {},
   "source": [
    "## The two columns in the data set, with the 'review' column as the audience's review on the movie and the 'sentiment' column determines if  the review was a positive or negative comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6eb073e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['review', 'sentiment']\n"
     ]
    }
   ],
   "source": [
    "print (list(imdb)) # Printing the list of the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3326afb6",
   "metadata": {},
   "source": [
    "# Converting the words in the dataset to all lower case letters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "759241d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb['review'] = imdb['review'].str.lower() #Converting the dataset into all lower case letters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9b995f",
   "metadata": {},
   "source": [
    "## We are pulling out the first review and sentiment to look at the contents. The review is text and the sentiment label is either negative or positive based on how the reviewer rated it on imdb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb7ae333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one of the other reviewers has mentioned that after watching just 1 oz episode you'll be hooked. they are right, as this is exactly what happened with me.<br /><br />the first thing that struck me about oz was its brutality and unflinching scenes of violence, which set in right from the word go. trust me, this is not a show for the faint hearted or timid. this show pulls no punches with regards to drugs, sex or violence. its is hardcore, in the classic use of the word.<br /><br />it is called oz as that is the nickname given to the oswald maximum security state penitentary. it focuses mainly on emerald city, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. em city is home to many..aryans, muslims, gangstas, latinos, christians, italians, irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />i would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. forget pretty pictures painted for mainstream audiences, forget charm, forget romance...oz doesn't mess around. the first episode i ever saw struck me as so nasty it was surreal, i couldn't say i was ready for it, but as i watched more, i developed a taste for oz, and got accustomed to the high levels of graphic violence. not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) watching oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_review = imdb.iloc[0] #promting the first paragraph of the dataset \n",
    "(ex_review['review']) #printing the paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "819cd2fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positive'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(ex_review['sentiment']) #propmting the function to dtermine wether the examples review was positive or negative"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b154c69",
   "metadata": {},
   "source": [
    "## Using Tokenization to split the review text into individual words, then punctuating and gramatically analyzing and correcting them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4dc89cb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'other',\n",
       " 'reviewers',\n",
       " 'has',\n",
       " 'mentioned',\n",
       " 'that',\n",
       " 'after',\n",
       " 'watching',\n",
       " 'just',\n",
       " '1',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'you',\n",
       " \"'ll\",\n",
       " 'be',\n",
       " 'hooked',\n",
       " '.',\n",
       " 'they',\n",
       " 'are',\n",
       " 'right',\n",
       " ',',\n",
       " 'as',\n",
       " 'this',\n",
       " 'is',\n",
       " 'exactly',\n",
       " 'what',\n",
       " 'happened',\n",
       " 'with',\n",
       " 'me.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'the',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'that',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'about',\n",
       " 'oz',\n",
       " 'was',\n",
       " 'its',\n",
       " 'brutality',\n",
       " 'and',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'of',\n",
       " 'violence',\n",
       " ',',\n",
       " 'which',\n",
       " 'set',\n",
       " 'in',\n",
       " 'right',\n",
       " 'from',\n",
       " 'the',\n",
       " 'word',\n",
       " 'go',\n",
       " '.',\n",
       " 'trust',\n",
       " 'me',\n",
       " ',',\n",
       " 'this',\n",
       " 'is',\n",
       " 'not',\n",
       " 'a',\n",
       " 'show',\n",
       " 'for',\n",
       " 'the',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'or',\n",
       " 'timid',\n",
       " '.',\n",
       " 'this',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'no',\n",
       " 'punches',\n",
       " 'with',\n",
       " 'regards',\n",
       " 'to',\n",
       " 'drugs',\n",
       " ',',\n",
       " 'sex',\n",
       " 'or',\n",
       " 'violence',\n",
       " '.',\n",
       " 'its',\n",
       " 'is',\n",
       " 'hardcore',\n",
       " ',',\n",
       " 'in',\n",
       " 'the',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'of',\n",
       " 'the',\n",
       " 'word.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'it',\n",
       " 'is',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'as',\n",
       " 'that',\n",
       " 'is',\n",
       " 'the',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'to',\n",
       " 'the',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary',\n",
       " '.',\n",
       " 'it',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'on',\n",
       " 'emerald',\n",
       " 'city',\n",
       " ',',\n",
       " 'an',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'of',\n",
       " 'the',\n",
       " 'prison',\n",
       " 'where',\n",
       " 'all',\n",
       " 'the',\n",
       " 'cells',\n",
       " 'have',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'and',\n",
       " 'face',\n",
       " 'inwards',\n",
       " ',',\n",
       " 'so',\n",
       " 'privacy',\n",
       " 'is',\n",
       " 'not',\n",
       " 'high',\n",
       " 'on',\n",
       " 'the',\n",
       " 'agenda',\n",
       " '.',\n",
       " 'em',\n",
       " 'city',\n",
       " 'is',\n",
       " 'home',\n",
       " 'to',\n",
       " 'many',\n",
       " '..',\n",
       " 'aryans',\n",
       " ',',\n",
       " 'muslims',\n",
       " ',',\n",
       " 'gangstas',\n",
       " ',',\n",
       " 'latinos',\n",
       " ',',\n",
       " 'christians',\n",
       " ',',\n",
       " 'italians',\n",
       " ',',\n",
       " 'irish',\n",
       " 'and',\n",
       " 'more',\n",
       " '....',\n",
       " 'so',\n",
       " 'scuffles',\n",
       " ',',\n",
       " 'death',\n",
       " 'stares',\n",
       " ',',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'and',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'are',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away.',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " '<',\n",
       " 'br',\n",
       " '/',\n",
       " '>',\n",
       " 'i',\n",
       " 'would',\n",
       " 'say',\n",
       " 'the',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'of',\n",
       " 'the',\n",
       " 'show',\n",
       " 'is',\n",
       " 'due',\n",
       " 'to',\n",
       " 'the',\n",
       " 'fact',\n",
       " 'that',\n",
       " 'it',\n",
       " 'goes',\n",
       " 'where',\n",
       " 'other',\n",
       " 'shows',\n",
       " 'would',\n",
       " \"n't\",\n",
       " 'dare',\n",
       " '.',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'for',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " ',',\n",
       " 'forget',\n",
       " 'charm',\n",
       " ',',\n",
       " 'forget',\n",
       " 'romance',\n",
       " '...',\n",
       " 'oz',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'mess',\n",
       " 'around',\n",
       " '.',\n",
       " 'the',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'i',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'me',\n",
       " 'as',\n",
       " 'so',\n",
       " 'nasty',\n",
       " 'it',\n",
       " 'was',\n",
       " 'surreal',\n",
       " ',',\n",
       " 'i',\n",
       " 'could',\n",
       " \"n't\",\n",
       " 'say',\n",
       " 'i',\n",
       " 'was',\n",
       " 'ready',\n",
       " 'for',\n",
       " 'it',\n",
       " ',',\n",
       " 'but',\n",
       " 'as',\n",
       " 'i',\n",
       " 'watched',\n",
       " 'more',\n",
       " ',',\n",
       " 'i',\n",
       " 'developed',\n",
       " 'a',\n",
       " 'taste',\n",
       " 'for',\n",
       " 'oz',\n",
       " ',',\n",
       " 'and',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'to',\n",
       " 'the',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'of',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " '.',\n",
       " 'not',\n",
       " 'just',\n",
       " 'violence',\n",
       " ',',\n",
       " 'but',\n",
       " 'injustice',\n",
       " '(',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " 'who',\n",
       " \"'ll\",\n",
       " 'be',\n",
       " 'sold',\n",
       " 'out',\n",
       " 'for',\n",
       " 'a',\n",
       " 'nickel',\n",
       " ',',\n",
       " 'inmates',\n",
       " 'who',\n",
       " \"'ll\",\n",
       " 'kill',\n",
       " 'on',\n",
       " 'order',\n",
       " 'and',\n",
       " 'get',\n",
       " 'away',\n",
       " 'with',\n",
       " 'it',\n",
       " ',',\n",
       " 'well',\n",
       " 'mannered',\n",
       " ',',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'being',\n",
       " 'turned',\n",
       " 'into',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'to',\n",
       " 'their',\n",
       " 'lack',\n",
       " 'of',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'or',\n",
       " 'prison',\n",
       " 'experience',\n",
       " ')',\n",
       " 'watching',\n",
       " 'oz',\n",
       " ',',\n",
       " 'you',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'with',\n",
       " 'what',\n",
       " 'is',\n",
       " 'uncomfortable',\n",
       " 'viewing',\n",
       " '....',\n",
       " 'thats',\n",
       " 'if',\n",
       " 'you',\n",
       " 'can',\n",
       " 'get',\n",
       " 'in',\n",
       " 'touch',\n",
       " 'with',\n",
       " 'your',\n",
       " 'darker',\n",
       " 'side',\n",
       " '.']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk #Importing the library\n",
    "nltk.download\n",
    "(nltk.word_tokenize(ex_review['review'])) #applying the function 'word_tokenize' from the library to seperate and punctuate the words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6365f816",
   "metadata": {},
   "source": [
    "## We will again apply the function 'word_tokenize', then we will also strip out non alphanumeric words/characters (eliminating numbers and fixing punctuation) using .isalpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3479d78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'of', 'the', 'other', 'reviewers', 'has', 'mentioned', 'that', 'after', 'watching', 'just', 'oz', 'episode', 'you', 'be', 'hooked', 'they', 'are', 'right', 'as', 'this', 'is', 'exactly', 'what', 'happened', 'with', 'br', 'br', 'the', 'first', 'thing', 'that', 'struck', 'me', 'about', 'oz', 'was', 'its', 'brutality', 'and', 'unflinching', 'scenes', 'of', 'violence', 'which', 'set', 'in', 'right', 'from', 'the', 'word', 'go', 'trust', 'me', 'this', 'is', 'not', 'a', 'show', 'for', 'the', 'faint', 'hearted', 'or', 'timid', 'this', 'show', 'pulls', 'no', 'punches', 'with', 'regards', 'to', 'drugs', 'sex', 'or', 'violence', 'its', 'is', 'hardcore', 'in', 'the', 'classic', 'use', 'of', 'the', 'br', 'br', 'it', 'is', 'called', 'oz', 'as', 'that', 'is', 'the', 'nickname', 'given', 'to', 'the', 'oswald', 'maximum', 'security', 'state', 'penitentary', 'it', 'focuses', 'mainly', 'on', 'emerald', 'city', 'an', 'experimental', 'section', 'of', 'the', 'prison', 'where', 'all', 'the', 'cells', 'have', 'glass', 'fronts', 'and', 'face', 'inwards', 'so', 'privacy', 'is', 'not', 'high', 'on', 'the', 'agenda', 'em', 'city', 'is', 'home', 'to', 'many', 'aryans', 'muslims', 'gangstas', 'latinos', 'christians', 'italians', 'irish', 'and', 'more', 'so', 'scuffles', 'death', 'stares', 'dodgy', 'dealings', 'and', 'shady', 'agreements', 'are', 'never', 'far', 'br', 'br', 'i', 'would', 'say', 'the', 'main', 'appeal', 'of', 'the', 'show', 'is', 'due', 'to', 'the', 'fact', 'that', 'it', 'goes', 'where', 'other', 'shows', 'would', 'dare', 'forget', 'pretty', 'pictures', 'painted', 'for', 'mainstream', 'audiences', 'forget', 'charm', 'forget', 'romance', 'oz', 'does', 'mess', 'around', 'the', 'first', 'episode', 'i', 'ever', 'saw', 'struck', 'me', 'as', 'so', 'nasty', 'it', 'was', 'surreal', 'i', 'could', 'say', 'i', 'was', 'ready', 'for', 'it', 'but', 'as', 'i', 'watched', 'more', 'i', 'developed', 'a', 'taste', 'for', 'oz', 'and', 'got', 'accustomed', 'to', 'the', 'high', 'levels', 'of', 'graphic', 'violence', 'not', 'just', 'violence', 'but', 'injustice', 'crooked', 'guards', 'who', 'be', 'sold', 'out', 'for', 'a', 'nickel', 'inmates', 'who', 'kill', 'on', 'order', 'and', 'get', 'away', 'with', 'it', 'well', 'mannered', 'middle', 'class', 'inmates', 'being', 'turned', 'into', 'prison', 'bitches', 'due', 'to', 'their', 'lack', 'of', 'street', 'skills', 'or', 'prison', 'experience', 'watching', 'oz', 'you', 'may', 'become', 'comfortable', 'with', 'what', 'is', 'uncomfortable', 'viewing', 'thats', 'if', 'you', 'can', 'get', 'in', 'touch', 'with', 'your', 'darker', 'side']\n"
     ]
    }
   ],
   "source": [
    "def identify_tokens(row): #defining the function\n",
    "    review = row['review']  #defining 'review and applying 'row' to the 'review' dataset\n",
    "    tokens = nltk.word_tokenize(review) #defining 'tokens' and applying the function 'word_tokenize' to the 'review' \n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    return token_words\n",
    "imdb['words'] = imdb.apply(identify_tokens, axis=1) #applying the 'identify_tokens' function to 'words' in the IMDB dataset\n",
    "print(imdb['words'][0]) #printing out the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f686c2bf",
   "metadata": {},
   "source": [
    "## This is an example of stemming, it reduces related words to a common stem. It is useful to test accuracy with and without stemming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84a00c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['frighten', 'frighten', 'frighten']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer #importing the 'stem' function from the NLTK library\n",
    "stemming = PorterStemmer() #defining 'stemming'\n",
    "my_list = ['frightening', 'frightened', 'frightens'] #Making an example list\n",
    "\n",
    "print ([stemming.stem(word) for word in my_list]) #Printing the example list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18758bfa",
   "metadata": {},
   "source": [
    "# Applying the functions I called in the 'example' row above, to our IMDB dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7478e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_list(row): #Prompting 'stem_list' to apply on the people\n",
    "    my_list = row['words'] #Defining the variable word 'my_list'\n",
    "    stemmed_list = [stemming.stem(wo rd) for word in my_list] #Prompting stemmed_list applying the '.stem' function to stem the new dataframe\n",
    "    return (stemmed_list) #Returnning the 'stemmed list'\n",
    "imdb['stemmed_words'] = imdb.apply(stem_list, axis=1) # applying 'stem_list' to the newly dataframe 'stemmed_words' so it could stem the dataframe using it's function's application on the dataframe\n",
    "\n",
    "print(imdb['stemmed_words'][0]) #printing the IMDB Dataset which was saved as 'stemmed_words'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a84c986",
   "metadata": {},
   "source": [
    "## Removing the stop words from the set. ‘Stop words’ are regularly used words that are unlikely to have any benefit in natural language processing. These includes words such as ‘a’, ‘the’, ‘is’. We will define a function and apply it to our Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8243cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['one', 'review', 'ha', 'mention', 'watch', 'oz', 'episod', 'hook', 'right', 'thi', 'exactli', 'happen', 'br', 'br', 'first', 'thing', 'struck', 'oz', 'wa', 'brutal', 'unflinch', 'scene', 'violenc', 'set', 'right', 'word', 'go', 'trust', 'thi', 'show', 'faint', 'heart', 'timid', 'thi', 'show', 'pull', 'punch', 'regard', 'drug', 'sex', 'violenc', 'hardcor', 'classic', 'use', 'br', 'br', 'call', 'oz', 'nicknam', 'given', 'oswald', 'maximum', 'secur', 'state', 'penitentari', 'focus', 'mainli', 'emerald', 'citi', 'experiment', 'section', 'prison', 'cell', 'glass', 'front', 'face', 'inward', 'privaci', 'high', 'agenda', 'em', 'citi', 'home', 'mani', 'aryan', 'muslim', 'gangsta', 'latino', 'christian', 'italian', 'irish', 'scuffl', 'death', 'stare', 'dodgi', 'deal', 'shadi', 'agreement', 'never', 'far', 'br', 'br', 'would', 'say', 'main', 'appeal', 'show', 'due', 'fact', 'goe', 'show', 'would', 'dare', 'forget', 'pretti', 'pictur', 'paint', 'mainstream', 'audienc', 'forget', 'charm', 'forget', 'romanc', 'oz', 'doe', 'mess', 'around', 'first', 'episod', 'ever', 'saw', 'struck', 'nasti', 'wa', 'surreal', 'could', 'say', 'wa', 'readi', 'watch', 'develop', 'tast', 'oz', 'got', 'accustom', 'high', 'level', 'graphic', 'violenc', 'violenc', 'injustic', 'crook', 'guard', 'sold', 'nickel', 'inmat', 'kill', 'order', 'get', 'away', 'well', 'manner', 'middl', 'class', 'inmat', 'turn', 'prison', 'bitch', 'due', 'lack', 'street', 'skill', 'prison', 'experi', 'watch', 'oz', 'may', 'becom', 'comfort', 'uncomfort', 'view', 'get', 'touch', 'darker', 'side']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords # importing 'stopwords' and applying the 'corpus' function \n",
    "stops = set(stopwords.words(\"english\"))  # Creating a set of words we will call 'stops'                \n",
    "\n",
    "def remove_stops(row): #Importing 'remove_stops'\n",
    "    my_list = row['stemmed_words'] #'Making my lsit'\n",
    "    meaningful_words = [w for w in my_list if not w in stops] #Defining 'meaningful words' \n",
    "    return (meaningful_words) #'Returning any meaningful words'\n",
    "imdb['stem_meaningful'] = imdb.apply(remove_stops, axis=1) #'Applying the stopwords function to the dataset'\n",
    "\n",
    "print(imdb['stem_meaningful'][0]) #Printing the datafrane"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0ff6d4",
   "metadata": {},
   "source": [
    "## Now re-joining the meaningful stemmed words by using the function rejoin_words, and put all our stemmed work into a training go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a5b6e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one review ha mention watch oz episod hook right thi exactli happen br br first thing struck oz wa brutal unflinch scene violenc set right word go trust thi show faint heart timid thi show pull punch regard drug sex violenc hardcor classic use br br call oz nicknam given oswald maximum secur state penitentari focus mainli emerald citi experiment section prison cell glass front face inward privaci high agenda em citi home mani aryan muslim gangsta latino christian italian irish scuffl death stare dodgi deal shadi agreement never far br br would say main appeal show due fact goe show would dare forget pretti pictur paint mainstream audienc forget charm forget romanc oz doe mess around first episod ever saw struck nasti wa surreal could say wa readi watch develop tast oz got accustom high level graphic violenc violenc injustic crook guard sold nickel inmat kill order get away well manner middl class inmat turn prison bitch due lack street skill prison experi watch oz may becom comfort uncomfort view get touch darker side\n"
     ]
    }
   ],
   "source": [
    "def rejoin_words(row): #Applying a function in the \n",
    "    my_list = row['stem_meaningful'#My list is the variable for my data frame above\"\n",
    "    joined_words = ( \" \".join(my_list))#Joined_words is the function \n",
    "    return joined_words #Returns 'joined_mwords', which returns your meaningful joint words\n",
    "\n",
    "imdb['processed'] = imdb.apply(rejoin_words, axis=1) #applying through 'rejoin_words' to the data frame\n",
    "\n",
    "print(imdb['processed'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888e7f5b",
   "metadata": {},
   "source": [
    "# Saving the new updated IMDB dataset as a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a1c5c3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb.to_csv('imdb_processed.csv', index=False) #Saving the new and updated code to the original names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a0491e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
